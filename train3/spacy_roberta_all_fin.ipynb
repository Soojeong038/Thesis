{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqN-itbgdu9P",
        "outputId": "4ddd7e57-f555-4c18-819a-1982ba32c0aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy[transformers] in /usr/local/lib/python3.7/dist-packages (3.4.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (3.0.10)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (3.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (4.64.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (57.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.10.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (8.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.21.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (0.10.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (0.6.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.4.5)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (4.1.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (3.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.0.9)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.0.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.11.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.0.7)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (0.4.2)\n",
            "Collecting spacy-transformers<1.2.0,>=1.1.2\n",
            "  Downloading spacy_transformers-1.1.8-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 569 kB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy[transformers]) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy[transformers]) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy[transformers]) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (2.10)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (1.12.1+cu113)\n",
            "Collecting transformers<4.22.0,>=3.4.0\n",
            "  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 62.8 MB/s \n",
            "\u001b[?25hCollecting spacy-alignments<1.0.0,>=0.7.2\n",
            "  Downloading spacy_alignments-0.8.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy[transformers]) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy[transformers]) (0.0.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (4.13.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 71.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 57.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (3.8.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy[transformers]) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy[transformers]) (2.0.1)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, spacy-alignments, spacy-transformers\n",
            "Successfully installed huggingface-hub-0.11.0 spacy-alignments-0.8.6 spacy-transformers-1.1.8 tokenizers-0.12.1 transformers-4.21.3\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy[transformers]\n",
        "import spacy_transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train config_roberta.cfg --gpu-id 0 --paths.train train_sum.spacy --paths.dev dev_sum.spacy --output ./output_roberta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCtihnGed5yz",
        "outputId": "2b2bc359-7081-4684-e63e-aa033e5b25a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: output_roberta\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: output_roberta\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-11-19 16:39:00,283] [INFO] Set up nlp object from config\n",
            "INFO:spacy:Set up nlp object from config\n",
            "[2022-11-19 16:39:00,297] [INFO] Pipeline: ['transformer', 'ner']\n",
            "INFO:spacy:Pipeline: ['transformer', 'ner']\n",
            "[2022-11-19 16:39:00,301] [INFO] Created vocabulary\n",
            "INFO:spacy:Created vocabulary\n",
            "[2022-11-19 16:39:00,302] [INFO] Finished initializing nlp object\n",
            "INFO:spacy:Finished initializing nlp object\n",
            "Downloading config.json: 100% 615/615 [00:00<00:00, 612kB/s]\n",
            "Downloading sentencepiece.bpe.model: 100% 4.83M/4.83M [00:01<00:00, 3.19MB/s]\n",
            "Downloading tokenizer.json: 100% 8.68M/8.68M [00:01<00:00, 4.56MB/s]\n",
            "Downloading pytorch_model.bin: 100% 1.04G/1.04G [00:16<00:00, 69.2MB/s]\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2022-11-19 16:40:02,772] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "INFO:spacy:Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving results to saveoutput_roberta_all.txt\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "tcmalloc: large alloc 1200103424 bytes == 0x10b3da000 @  0x7f498234a615 0x58ead6 0x4f355e 0x58f8af 0x58fb26 0x7f490c17d07f 0x7f490c14d974 0x7f48ca41bef5 0x7f48ca416441 0x7f48ca41d549 0x7f490c14df3b 0x7f490bdd7f61 0x58f6e4 0x590691 0x510946 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x510325 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x58fd37\n",
            "tcmalloc: large alloc 1500135424 bytes == 0x152c5c000 @  0x7f498234a615 0x58ead6 0x4f355e 0x58f8af 0x58fb26 0x7f490c17d07f 0x7f490c14d974 0x7f48ca41bef5 0x7f48ca416441 0x7f48ca41d549 0x7f490c14df3b 0x7f490bdd7f61 0x58f6e4 0x590691 0x510946 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x510325 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x58fd37\n",
            "tcmalloc: large alloc 2224521216 bytes == 0x7f4427548000 @  0x7f498234a2a4 0x7f4976ba8193 0x7f4976ba9c5d 0x7f4976ba6435 0x7f4976ba6bde 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x510325 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x5b575e 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482\n",
            "tcmalloc: large alloc 2268823552 bytes == 0x14edb6000 @  0x7f498234a2a4 0x7f4976ba8193 0x7f4976ba8320 0x7f4976ba8320 0x7f4976ba9c5d 0x7f4976ba6435 0x7f4976ba6bde 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x510325 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x5b575e 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x510325\n",
            "  0       0         446.20    833.95    0.00    0.00    0.00    0.00\n",
            "tcmalloc: large alloc 2224521216 bytes == 0x7f4427548000 @  0x7f498234a2a4 0x7f4976ba8193 0x7f4976ba9c5d 0x7f4976ba6435 0x7f4976ba6bde 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x510325 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x5b575e 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482\n",
            "tcmalloc: large alloc 2268823552 bytes == 0x7f4342c48000 @  0x7f498234a2a4 0x7f4976ba8193 0x7f4976ba8320 0x7f4976ba8320 0x7f4976ba9c5d 0x7f4976ba6435 0x7f4976ba6bde 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x510325 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x5b575e 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x510325\n",
            "  0      50       17118.75  29067.10   39.67   94.70   25.09    0.40\n",
            "tcmalloc: large alloc 2224521216 bytes == 0x7f4342c48000 @  0x7f498234a2a4 0x7f4976ba8193 0x7f4976ba9c5d 0x7f4976ba6435 0x7f4976ba6bde 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x510325 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x5b575e 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482\n",
            "  0     100        1643.30   1741.77   70.68   67.14   74.60    0.71\n",
            "  0     150         454.72    784.01   83.98   81.35   86.78    0.84\n",
            "  0     200         252.99    559.38   89.47   87.97   91.02    0.89\n",
            "  0     250         248.31    549.33   89.87   88.07   91.75    0.90\n",
            "  0     300         255.23    522.18   91.44   89.56   93.40    0.91\n",
            "  1     350         195.58    375.88   91.44   89.03   93.99    0.91\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output_roberta/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy evaluate /content/drive/MyDrive/output_roberta/model-best test_sum.spacy --gpu-id 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX2yTNG3uJ_u",
        "outputId": "e9612e7a-4a6c-481b-9fa1-15f3c1c0931f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "tcmalloc: large alloc 1134411776 bytes == 0x77a64000 @  0x7f67392721e7 0x4b2590 0x5ad01c 0x5dcfef 0x58f92b 0x590c33 0x5e48ac 0x4d20fa 0x51041f 0x5b575e 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482 0x5b575e 0x4bad0a 0x50e18c 0x5b575e 0x58ff2e 0x510325\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   89.29 \n",
            "NER R   93.17 \n",
            "NER F   91.19 \n",
            "SPEED   4834  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "          P       R       F\n",
            "ORG   89.29   93.17   91.19\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy evaluate /content/drive/MyDrive/output_roberta/model-best test_data_shuffle.spacy --gpu-id 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9310henuV5e",
        "outputId": "cd461370-fe95-499f-c3cc-35f761a958e1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "tcmalloc: large alloc 1134411776 bytes == 0x77b2e000 @  0x7f736d19f1e7 0x4b2590 0x5ad01c 0x5dcfef 0x58f92b 0x590c33 0x5e48ac 0x4d20fa 0x51041f 0x5b575e 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482 0x5b575e 0x4bad0a 0x50e18c 0x5b575e 0x58ff2e 0x510325\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   94.24 \n",
            "NER R   93.84 \n",
            "NER F   94.04 \n",
            "SPEED   4881  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "          P       R       F\n",
            "ORG   94.24   93.84   94.04\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "with patience = 100"
      ],
      "metadata": {
        "id": "-8M2I_xd4w_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train config_roberta.cfg --gpu-id 0 --paths.train train_sum.spacy --paths.dev dev_sum.spacy --output ./output_roberta_100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUxWj39l438O",
        "outputId": "56637ef9-7797-438e-b93e-7ee8912a34ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: output_roberta_100\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-11-19 17:18:55,588] [INFO] Set up nlp object from config\n",
            "INFO:spacy:Set up nlp object from config\n",
            "[2022-11-19 17:18:55,600] [INFO] Pipeline: ['transformer', 'ner']\n",
            "INFO:spacy:Pipeline: ['transformer', 'ner']\n",
            "[2022-11-19 17:18:55,604] [INFO] Created vocabulary\n",
            "INFO:spacy:Created vocabulary\n",
            "[2022-11-19 17:18:55,605] [INFO] Finished initializing nlp object\n",
            "INFO:spacy:Finished initializing nlp object\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2022-11-19 17:19:17,875] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "INFO:spacy:Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving results to saveoutput_roberta_all.txt\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "tcmalloc: large alloc 1200103424 bytes == 0x109ba6000 @  0x7fa7010b7615 0x58ead6 0x4f355e 0x58f8af 0x58fb26 0x7fa68aeea07f 0x7fa68aeba974 0x7fa64a41bef5 0x7fa64a416441 0x7fa64a41d549 0x7fa68aebaf3b 0x7fa68ab44f61 0x58f6e4 0x590691 0x510946 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x510325 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x58fd37\n",
            "tcmalloc: large alloc 1500135424 bytes == 0x151428000 @  0x7fa7010b7615 0x58ead6 0x4f355e 0x58f8af 0x58fb26 0x7fa68aeea07f 0x7fa68aeba974 0x7fa64a41bef5 0x7fa64a416441 0x7fa64a41d549 0x7fa68aebaf3b 0x7fa68ab44f61 0x58f6e4 0x590691 0x510946 0x5b575e 0x58ff2e 0x50c4fc 0x5b4ee6 0x58ff2e 0x510325 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x58fd37\n",
            "tcmalloc: large alloc 2224521216 bytes == 0x7fa1a5688000 @  0x7fa7010b72a4 0x7fa6f5915193 0x7fa6f5916c5d 0x7fa6f5913435 0x7fa6f5913bde 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x510325 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x5b575e 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482\n",
            "tcmalloc: large alloc 2268823552 bytes == 0x14d582000 @  0x7fa7010b72a4 0x7fa6f5915193 0x7fa6f5915320 0x7fa6f5915320 0x7fa6f5916c5d 0x7fa6f5913435 0x7fa6f5913bde 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x510325 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x5b575e 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x510325\n",
            "  0       0         446.19    833.95    0.00    0.00    0.00    0.00\n",
            "tcmalloc: large alloc 2224521216 bytes == 0x7fa1a5688000 @  0x7fa7010b72a4 0x7fa6f5915193 0x7fa6f5916c5d 0x7fa6f5913435 0x7fa6f5913bde 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x510325 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x5b575e 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482\n",
            "tcmalloc: large alloc 2268823552 bytes == 0x7fa0c0c48000 @  0x7fa7010b72a4 0x7fa6f5915193 0x7fa6f5915320 0x7fa6f5915320 0x7fa6f5916c5d 0x7fa6f5913435 0x7fa6f5913bde 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x510325 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x5b575e 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x510325\n",
            "  0      50       17118.69  29066.92   39.72   94.71   25.13    0.40\n",
            "tcmalloc: large alloc 2224521216 bytes == 0x7fa0c0c48000 @  0x7fa7010b72a4 0x7fa6f5915193 0x7fa6f5916c5d 0x7fa6f5913435 0x7fa6f5913bde 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x50d482 0x58fd37 0x510325 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x58fd37 0x50ca37 0x5b575e 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482\n",
            "  0     100        1691.58   1776.39   69.79   66.59   73.31    0.70\n",
            "  0     150         415.78    755.97   83.76   80.91   86.82    0.84\n",
            "  0     200         264.40    577.93   90.15   89.27   91.05    0.90\n",
            "  0     250         263.04    530.98   88.99   86.29   91.87    0.89\n",
            "  0     300         268.73    538.36   91.30   90.19   92.43    0.91\n",
            "  1     350         179.02    378.54   90.87   88.63   93.22    0.91\n",
            "  1     400         173.96    462.40   92.65   90.68   94.71    0.93\n",
            "  1     450         152.41    370.71   92.64   93.58   91.72    0.93\n",
            "  1     500         166.38    377.95   93.68   93.46   93.91    0.94\n",
            "  1     550         144.86    331.82   93.24   92.27   94.23    0.93\n",
            "  1     600         141.42    312.58   94.19   93.48   94.90    0.94\n",
            "  2     650         130.22    308.77   94.36   93.43   95.31    0.94\n",
            "  2     700         133.97    266.57   94.27   92.81   95.77    0.94\n",
            "  2     750         104.42    230.21   94.22   92.17   96.36    0.94\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output_roberta_100/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy evaluate /content/drive/MyDrive/output_roberta_100/model-best test_sum.spacy --gpu-id 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-3PZ6cPGYKY",
        "outputId": "ecc54431-f5c0-4639-cd51-e5595bac4dfc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "tcmalloc: large alloc 1134411776 bytes == 0x78fde000 @  0x7ff1d2bce1e7 0x4b2590 0x5ad01c 0x5dcfef 0x58f92b 0x590c33 0x5e48ac 0x4d20fa 0x51041f 0x5b575e 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482 0x5b575e 0x4bad0a 0x50e18c 0x5b575e 0x58ff2e 0x510325\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   93.01 \n",
            "NER R   94.99 \n",
            "NER F   93.99 \n",
            "SPEED   4804  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "          P       R       F\n",
            "ORG   93.01   94.99   93.99\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy evaluate /content/drive/MyDrive/output_roberta_100/model-best test_data_shuffle.spacy --gpu-id 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EylSGJV_HR_n",
        "outputId": "d254f001-1072-46a5-d2ee-4bfe40fefd76"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "tcmalloc: large alloc 1134411776 bytes == 0x77bd6000 @  0x7fdba8b661e7 0x4b2590 0x5ad01c 0x5dcfef 0x58f92b 0x590c33 0x5e48ac 0x4d20fa 0x51041f 0x5b575e 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x510325 0x5b575e 0x58ff2e 0x50d482 0x5b575e 0x4bad0a 0x50e18c 0x5b575e 0x58ff2e 0x510325\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   94.62 \n",
            "NER R   96.54 \n",
            "NER F   95.57 \n",
            "SPEED   4872  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "          P       R       F\n",
            "ORG   94.62   96.54   95.57\n",
            "\n"
          ]
        }
      ]
    }
  ]
}