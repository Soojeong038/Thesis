{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c9cff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = './cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3404220e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sooje\\anaconda3\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "# !python -m spacy download de_core_news_sm\n",
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cbad2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2cd34d",
   "metadata": {},
   "source": [
    "#  Jsonl to IOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df685255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from Jsonl_to_IOB import *\n",
    "path = 'all.jsonl'\n",
    "data = get_data(path)\n",
    "tokenized = tokenized_output(data)\n",
    "tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b8eba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(data):\n",
    "    count = 0 \n",
    "    i=0\n",
    "    starts = [x['start_offset'] for x in data['entities']]\n",
    "    ends = [x['end_offset'] for x in data['entities']]\n",
    "    starts.append(99999)\n",
    "    ends.append(99999)\n",
    "    \n",
    "    sen_temp = []\n",
    "    tag_temp = []\n",
    "    \n",
    "    text = data['text']\n",
    "    if text.startswith(\" \"):\n",
    "        text = text[1:]\n",
    "        count = 1\n",
    "    doc = nlp(text)\n",
    "    \n",
    "\n",
    "    for t in doc:\n",
    "        sen_temp.append(t.text)\n",
    "        if count == starts[i]:\n",
    "            tag_temp.append('B-ORG')\n",
    "            count = count+len(t.text)+1\n",
    "            if count > ends[i]:\n",
    "                i += 1\n",
    "                \n",
    "        elif count > starts[i] and count < ends[i]:\n",
    "            if tag_temp[-1] == 'O':\n",
    "                tag_temp.append('B-ORG')\n",
    "            else:\n",
    "                tag_temp.append('I-ORG')\n",
    "            count = count+len(t.text)+1\n",
    "            if count > ends[i]:\n",
    "                i += 1\n",
    "                \n",
    "        else:\n",
    "            tag_temp.append('O')\n",
    "            count = count+len(t.text)+1\n",
    "    \n",
    "    return sen_temp, tag_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b174b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "import json\n",
    "path = 'all.jsonl'\n",
    "\n",
    "with open(path,'r', encoding = 'utf-8') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07d61c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 26614,\n",
       " 'text': 'Maßnahmenbekanntgabe zu MA 40, Prüfung der Nebenbeschäftigungen',\n",
       " 'doc_id': 0,\n",
       " 'para_id': 0,\n",
       " 'entities': [{'id': 51631,\n",
       "   'label': 'ORG',\n",
       "   'start_offset': 24,\n",
       "   'end_offset': 29}],\n",
       " 'relations': [],\n",
       " 'Comments': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed62938c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Maßnahmenbekanntgabe',\n",
       "  'zu',\n",
       "  'MA',\n",
       "  '40',\n",
       "  ',',\n",
       "  'Prüfung',\n",
       "  'der',\n",
       "  'Nebenbeschäftigungen'],\n",
       " ['O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenization(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6810cbb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>para_id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Maßnahmenbekanntgabe, zu, MA, 40, ,, Prüfung,...</td>\n",
       "      <td>[O, O, B-ORG, I-ORG, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[INHALTSVERZEICHNIS]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[ABKÜRZUNGSVERZEICHNIS]</td>\n",
       "      <td>[O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[bzw., beziehungsweise, Nr., Nummer]</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[Erledigung, des, Prüfungsberichtes, Der, Stad...</td>\n",
       "      <td>[O, O, O, O, B-ORG, I-ORG, O, O, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>41</td>\n",
       "      <td>31</td>\n",
       "      <td>[Empfehlung, Nr., 8, Vor, Erstellung, eines, L...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>41</td>\n",
       "      <td>32</td>\n",
       "      <td>[Ergebnis, der, Prüfung, des, Stadtrechnungsho...</td>\n",
       "      <td>[O, O, O, O, B-ORG, I-ORG, O, O, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3702</th>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>[Empfehlung, Nr., 9, Die, Führung, von, Bautag...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>[Ergebnis, der, Prüfung, des, Stadtrechnungsho...</td>\n",
       "      <td>[O, O, O, O, B-ORG, I-ORG, O, O, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3704</th>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>[Der, Stadtrechnungshofdirektor, :, Mag, ., We...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3705 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_id  para_id                                             tokens  \\\n",
       "0          0        0  [Maßnahmenbekanntgabe, zu, MA, 40, ,, Prüfung,...   \n",
       "1          0        1                               [INHALTSVERZEICHNIS]   \n",
       "2          0        2                            [ABKÜRZUNGSVERZEICHNIS]   \n",
       "3          0        3               [bzw., beziehungsweise, Nr., Nummer]   \n",
       "4          0        4  [Erledigung, des, Prüfungsberichtes, Der, Stad...   \n",
       "...      ...      ...                                                ...   \n",
       "3700      41       31  [Empfehlung, Nr., 8, Vor, Erstellung, eines, L...   \n",
       "3701      41       32  [Ergebnis, der, Prüfung, des, Stadtrechnungsho...   \n",
       "3702      41       33  [Empfehlung, Nr., 9, Die, Führung, von, Bautag...   \n",
       "3703      41       34  [Ergebnis, der, Prüfung, des, Stadtrechnungsho...   \n",
       "3704      41       35  [Der, Stadtrechnungshofdirektor, :, Mag, ., We...   \n",
       "\n",
       "                                               ner_tags  \n",
       "0                      [O, O, B-ORG, I-ORG, O, O, O, O]  \n",
       "1                                                   [O]  \n",
       "2                                                   [O]  \n",
       "3                                          [O, O, O, O]  \n",
       "4     [O, O, O, O, B-ORG, I-ORG, O, O, O, O, O, O, O...  \n",
       "...                                                 ...  \n",
       "3700  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3701  [O, O, O, O, B-ORG, I-ORG, O, O, O, O, O, O, O...  \n",
       "3702  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "3703  [O, O, O, O, B-ORG, I-ORG, O, O, O, O, O, O, O...  \n",
       "3704  [O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, O, ...  \n",
       "\n",
       "[3705 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "doc_id_list = []\n",
    "para_id_list = []\n",
    "txt_list = []\n",
    "tag_list = []\n",
    "\n",
    "for d in data:\n",
    "    doc_id_list.append(d['doc_id'])\n",
    "    para_id_list.append(d['para_id'])\n",
    "    txt, tag = tokenization(d)\n",
    "    txt_list.append(txt)\n",
    "    tag_list.append(tag)\n",
    "    \n",
    "tokenized = pd.DataFrame({'doc_id' : doc_id_list,\n",
    "                         'para_id': para_id_list,\n",
    "                         'tokens' : txt_list,\n",
    "                         'ner_tags' : tag_list})\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fbac35",
   "metadata": {},
   "source": [
    "# Preprocess for using transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d263a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-german-dbmdz-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2092f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding_dict = {'O': 0,\n",
    "                 'B-ORG':1,\n",
    "                'I-ORG':2}\n",
    "label_list = ['O','B-ORG','I-ORG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8c920494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels(data, label_encoding_dict):\n",
    "\n",
    "    tokenized_inputs = tokenizer(data[\"tokens\"],\n",
    "                        max_length = 128, padding = 'max_length',\n",
    "                        truncation=True, is_split_into_words=True)\n",
    "\n",
    "    label_id_temp = {}\n",
    "    for i, label in enumerate(data['ner_tags']):\n",
    "        label_id_temp.update({i:label})\n",
    "\n",
    "    word_ids = tokenized_inputs.word_ids(batch_index=0)\n",
    "\n",
    "    labels = []\n",
    "    for w_id in word_ids:\n",
    "        if w_id == None:\n",
    "            labels.append(-100)\n",
    "        else:\n",
    "            tag = label_id_temp[w_id]\n",
    "            labels.append(label_encoding_dict[tag])\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8237ca48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>para_id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Maßnahmenbekanntgabe, zu, MA, 40, ,, Prüfung,...</td>\n",
       "      <td>[O, O, B-ORG, I-ORG, O, O, O, O]</td>\n",
       "      <td>[102, 2400, 3366, 837, 1621, 205, 21669, 2161,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[INHALTSVERZEICHNIS]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[102, 5331, 30925, 22171, 3610, 949, 24626, 50...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[ABKÜRZUNGSVERZEICHNIS]</td>\n",
       "      <td>[O]</td>\n",
       "      <td>[102, 9059, 30918, 12939, 30945, 13895, 15853,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[bzw., beziehungsweise, Nr., Nummer]</td>\n",
       "      <td>[O, O, O, O]</td>\n",
       "      <td>[102, 2100, 566, 9542, 1559, 566, 5311, 103, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, -100, -100, -100, -10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[Erledigung, des, Prüfungsberichtes, Der, Stad...</td>\n",
       "      <td>[O, O, O, O, B-ORG, I-ORG, O, O, O, O, O, O, O...</td>\n",
       "      <td>[102, 8179, 3553, 132, 222, 17639, 15602, 3088...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>41</td>\n",
       "      <td>31</td>\n",
       "      <td>[Empfehlung, Nr., 8, Vor, Erstellung, eines, L...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[102, 11340, 1559, 566, 642, 445, 13248, 683, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>41</td>\n",
       "      <td>32</td>\n",
       "      <td>[Ergebnis, der, Prüfung, des, Stadtrechnungsho...</td>\n",
       "      <td>[O, O, O, O, B-ORG, I-ORG, O, O, O, O, O, O, O...</td>\n",
       "      <td>[102, 3942, 125, 6868, 222, 668, 24831, 1312, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 1, 1, 1, 1, 2, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3702</th>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>[Empfehlung, Nr., 9, Die, Führung, von, Bautag...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[102, 11340, 1559, 566, 680, 229, 5203, 195, 1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>[Ergebnis, der, Prüfung, des, Stadtrechnungsho...</td>\n",
       "      <td>[O, O, O, O, B-ORG, I-ORG, O, O, O, O, O, O, O...</td>\n",
       "      <td>[102, 3942, 125, 6868, 222, 668, 24831, 1312, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 1, 1, 1, 1, 2, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3704</th>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>[Der, Stadtrechnungshofdirektor, :, Mag, ., We...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, O, ...</td>\n",
       "      <td>[102, 351, 668, 24831, 1312, 9664, 853, 2707, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3705 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_id  para_id                                             tokens  \\\n",
       "0          0        0  [Maßnahmenbekanntgabe, zu, MA, 40, ,, Prüfung,...   \n",
       "1          0        1                               [INHALTSVERZEICHNIS]   \n",
       "2          0        2                            [ABKÜRZUNGSVERZEICHNIS]   \n",
       "3          0        3               [bzw., beziehungsweise, Nr., Nummer]   \n",
       "4          0        4  [Erledigung, des, Prüfungsberichtes, Der, Stad...   \n",
       "...      ...      ...                                                ...   \n",
       "3700      41       31  [Empfehlung, Nr., 8, Vor, Erstellung, eines, L...   \n",
       "3701      41       32  [Ergebnis, der, Prüfung, des, Stadtrechnungsho...   \n",
       "3702      41       33  [Empfehlung, Nr., 9, Die, Führung, von, Bautag...   \n",
       "3703      41       34  [Ergebnis, der, Prüfung, des, Stadtrechnungsho...   \n",
       "3704      41       35  [Der, Stadtrechnungshofdirektor, :, Mag, ., We...   \n",
       "\n",
       "                                               ner_tags  \\\n",
       "0                      [O, O, B-ORG, I-ORG, O, O, O, O]   \n",
       "1                                                   [O]   \n",
       "2                                                   [O]   \n",
       "3                                          [O, O, O, O]   \n",
       "4     [O, O, O, O, B-ORG, I-ORG, O, O, O, O, O, O, O...   \n",
       "...                                                 ...   \n",
       "3700  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3701  [O, O, O, O, B-ORG, I-ORG, O, O, O, O, O, O, O...   \n",
       "3702  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3703  [O, O, O, O, B-ORG, I-ORG, O, O, O, O, O, O, O...   \n",
       "3704  [O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, O, ...   \n",
       "\n",
       "                                              input_ids  \\\n",
       "0     [102, 2400, 3366, 837, 1621, 205, 21669, 2161,...   \n",
       "1     [102, 5331, 30925, 22171, 3610, 949, 24626, 50...   \n",
       "2     [102, 9059, 30918, 12939, 30945, 13895, 15853,...   \n",
       "3     [102, 2100, 566, 9542, 1559, 566, 5311, 103, 0...   \n",
       "4     [102, 8179, 3553, 132, 222, 17639, 15602, 3088...   \n",
       "...                                                 ...   \n",
       "3700  [102, 11340, 1559, 566, 642, 445, 13248, 683, ...   \n",
       "3701  [102, 3942, 125, 6868, 222, 668, 24831, 1312, ...   \n",
       "3702  [102, 11340, 1559, 566, 680, 229, 5203, 195, 1...   \n",
       "3703  [102, 3942, 125, 6868, 222, 668, 24831, 1312, ...   \n",
       "3704  [102, 351, 668, 24831, 1312, 9664, 853, 2707, ...   \n",
       "\n",
       "                                         token_type_ids  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "3700  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3701  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3702  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3703  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3704  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                         attention_mask  \\\n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...   \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "...                                                 ...   \n",
       "3700  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3701  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3702  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3703  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3704  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                                 labels  \n",
       "0     [-100, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [-100, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -10...  \n",
       "2     [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, ...  \n",
       "3     [-100, 0, 0, 0, 0, 0, 0, -100, -100, -100, -10...  \n",
       "4     [-100, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 0, ...  \n",
       "...                                                 ...  \n",
       "3700  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3701  [-100, 0, 0, 0, 0, 1, 1, 1, 1, 2, 0, 0, 0, 0, ...  \n",
       "3702  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3703  [-100, 0, 0, 0, 0, 1, 1, 1, 1, 2, 0, 0, 0, 0, ...  \n",
       "3704  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "\n",
       "[3705 rows x 8 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = tokenized.copy()\n",
    "train['input_ids'] = \"\"\n",
    "train['token_type_ids'] = \"\"\n",
    "train['attention_mask']= \"\"\n",
    "train['labels'] = \"\"\n",
    "\n",
    "for index, row in tokenized.iterrows():\n",
    "    inputs = align_labels(row,label_encoding_dict)\n",
    "    train.at[index,'input_ids'] = inputs['input_ids']\n",
    "    train.at[index,'token_type_ids'] = inputs['token_type_ids']\n",
    "    train.at[index,'attention_mask'] = inputs['attention_mask']\n",
    "    train.at[index,'labels'] = inputs['labels']\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0067a325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "train_drop = train.drop(['doc_id','para_id'],axis = 1)\n",
    "train_dataset = Dataset.from_pandas(train_drop)\n",
    "print(type(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bbfa49dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2964\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 741\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = train_dataset.train_test_split(test_size=0.2)\n",
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "238f44fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 2964\n",
       "})"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6c5826",
   "metadata": {},
   "source": [
    "# Fine-tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "96066a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be6a1bd13094239bcb9aa525c893eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-dbmdz-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-german-dbmdz-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import torch\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import accuracy_score\n",
    "# from seqeval.metrics import f1_score\n",
    "# from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_encoding_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "893aaebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1},\n",
       " 'PER': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1},\n",
       " 'micro avg': {'precision': 0.5, 'recall': 0.5, 'f1-score': 0.5, 'support': 2},\n",
       " 'macro avg': {'precision': 0.5, 'recall': 0.5, 'f1-score': 0.5, 'support': 2},\n",
       " 'weighted avg': {'precision': 0.5,\n",
       "  'recall': 0.5,\n",
       "  'f1-score': 0.5,\n",
       "  'support': 2}}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "y_true = [['B-PER', 'I-PER', 'O'], ['O', 'O', 'B-LOC']]\n",
    "y_pred = [['B-PER', 'O', 'O'], ['O', 'O', 'B-LOC']]\n",
    "result = classification_report(y_true, y_pred, output_dict = True)\n",
    "result['PER']\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6c67cfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 2964\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='279' max='279' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [279/279 2:25:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.047051</td>\n",
       "      <td>0.803057</td>\n",
       "      <td>0.900461</td>\n",
       "      <td>0.848975</td>\n",
       "      <td>1517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.051350</td>\n",
       "      <td>0.813827</td>\n",
       "      <td>0.884641</td>\n",
       "      <td>0.847757</td>\n",
       "      <td>1517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.054068</td>\n",
       "      <td>0.807556</td>\n",
       "      <td>0.901780</td>\n",
       "      <td>0.852071</td>\n",
       "      <td>1517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 741\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ORG': {'precision': 0.8030570252792475, 'recall': 0.9004614370468029, 'f1-score': 0.8489745183343691, 'support': 1517}, 'micro avg': {'precision': 0.8030570252792475, 'recall': 0.9004614370468029, 'f1-score': 0.8489745183343691, 'support': 1517}, 'macro avg': {'precision': 0.8030570252792475, 'recall': 0.9004614370468029, 'f1-score': 0.8489745183343691, 'support': 1517}, 'weighted avg': {'precision': 0.8030570252792475, 'recall': 0.9004614370468029, 'f1-score': 0.8489745183343691, 'support': 1517}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 741\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ORG': {'precision': 0.813826561552456, 'recall': 0.8846407382992749, 'f1-score': 0.8477574226152874, 'support': 1517}, 'micro avg': {'precision': 0.813826561552456, 'recall': 0.8846407382992749, 'f1-score': 0.8477574226152874, 'support': 1517}, 'macro avg': {'precision': 0.813826561552456, 'recall': 0.8846407382992749, 'f1-score': 0.8477574226152874, 'support': 1517}, 'weighted avg': {'precision': 0.813826561552456, 'recall': 0.8846407382992749, 'f1-score': 0.8477574226152874, 'support': 1517}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 741\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ORG': {'precision': 0.807556080283353, 'recall': 0.9017798286090969, 'f1-score': 0.8520710059171597, 'support': 1517}, 'micro avg': {'precision': 0.807556080283353, 'recall': 0.9017798286090969, 'f1-score': 0.8520710059171597, 'support': 1517}, 'macro avg': {'precision': 0.807556080283353, 'recall': 0.9017798286090969, 'f1-score': 0.8520710059171597, 'support': 1517}, 'weighted avg': {'precision': 0.807556080283353, 'recall': 0.9017798286090969, 'f1-score': 0.8520710059171597, 'support': 1517}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: tokens, ner_tags. If tokens, ner_tags are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 741\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 03:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ORG': {'precision': 0.807556080283353, 'recall': 0.9017798286090969, 'f1-score': 0.8520710059171597, 'support': 1517}, 'micro avg': {'precision': 0.807556080283353, 'recall': 0.9017798286090969, 'f1-score': 0.8520710059171597, 'support': 1517}, 'macro avg': {'precision': 0.807556080283353, 'recall': 0.9017798286090969, 'f1-score': 0.8520710059171597, 'support': 1517}, 'weighted avg': {'precision': 0.807556080283353, 'recall': 0.9017798286090969, 'f1-score': 0.8520710059171597, 'support': 1517}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.05406766012310982,\n",
       " 'eval_precision': 0.807556080283353,\n",
       " 'eval_recall': 0.9017798286090969,\n",
       " 'eval_f1-score': 0.8520710059171597,\n",
       " 'eval_support': 1517,\n",
       " 'eval_runtime': 213.0744,\n",
       " 'eval_samples_per_second': 3.478,\n",
       " 'eval_steps_per_second': 0.113,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [[label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "    true_labels = [[label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "    \n",
    "    result = classification_report(true_labels, true_predictions, output_dict = True)\n",
    "\n",
    "    print(result)\n",
    "    \n",
    "    return result['ORG']\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "args = TrainingArguments(\n",
    "    \"test-ner\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=1e-5,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=dset['train'],\n",
    "    eval_dataset=dset['test'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"Training...\")\n",
    "trainer.train()\n",
    "print(\"Evaluating...\")\n",
    "trainer.evaluate()\n",
    "# print(\"Saving...\")\n",
    "# trainer.save_model('un-ner.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "435974bd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at ./cache\\models--bert-base-german-dbmdz-cased\\snapshots\\1338901726062fab13465d4b37f0f0c55b662a78\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-german-dbmdz-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at ./cache\\models--bert-base-german-dbmdz-cased\\snapshots\\1338901726062fab13465d4b37f0f0c55b662a78\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-german-dbmdz-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at ./cache\\models--bert-base-german-dbmdz-cased\\snapshots\\1338901726062fab13465d4b37f0f0c55b662a78\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at bert-base-german-dbmdz-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-german-dbmdz-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'LABEL_1',\n",
       "  'score': 0.6156101,\n",
       "  'index': 1,\n",
       "  'word': 'Dabei',\n",
       "  'start': 0,\n",
       "  'end': 5},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.54003084,\n",
       "  'index': 2,\n",
       "  'word': 'war',\n",
       "  'start': 6,\n",
       "  'end': 9},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.50910103,\n",
       "  'index': 3,\n",
       "  'word': 'festzustellen',\n",
       "  'start': 10,\n",
       "  'end': 23},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.52891177,\n",
       "  'index': 4,\n",
       "  'word': ',',\n",
       "  'start': 24,\n",
       "  'end': 25},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.533248,\n",
       "  'index': 5,\n",
       "  'word': 'dass',\n",
       "  'start': 26,\n",
       "  'end': 30},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.53162944,\n",
       "  'index': 6,\n",
       "  'word': 'der',\n",
       "  'start': 31,\n",
       "  'end': 34},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.52718717,\n",
       "  'index': 7,\n",
       "  'word': 'in',\n",
       "  'start': 35,\n",
       "  'end': 37},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.5688556,\n",
       "  'index': 8,\n",
       "  'word': 'der',\n",
       "  'start': 38,\n",
       "  'end': 41},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.5575596,\n",
       "  'index': 9,\n",
       "  'word': 'Maßnahmen',\n",
       "  'start': 42,\n",
       "  'end': 51},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.61140376,\n",
       "  'index': 10,\n",
       "  'word': '##bek',\n",
       "  'start': 51,\n",
       "  'end': 54},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.5468911,\n",
       "  'index': 11,\n",
       "  'word': '##annt',\n",
       "  'start': 54,\n",
       "  'end': 58},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.5126836,\n",
       "  'index': 12,\n",
       "  'word': '##gabe',\n",
       "  'start': 58,\n",
       "  'end': 62},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.5456423,\n",
       "  'index': 13,\n",
       "  'word': 'geäußert',\n",
       "  'start': 63,\n",
       "  'end': 71},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.5652353,\n",
       "  'index': 14,\n",
       "  'word': '##e',\n",
       "  'start': 71,\n",
       "  'end': 72},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.5170834,\n",
       "  'index': 15,\n",
       "  'word': 'Stand',\n",
       "  'start': 73,\n",
       "  'end': 78},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.60020256,\n",
       "  'index': 16,\n",
       "  'word': 'der',\n",
       "  'start': 79,\n",
       "  'end': 82},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.58273584,\n",
       "  'index': 17,\n",
       "  'word': 'Umsetzung',\n",
       "  'start': 83,\n",
       "  'end': 92},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.611215,\n",
       "  'index': 18,\n",
       "  'word': 'mit',\n",
       "  'start': 93,\n",
       "  'end': 96},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.5632011,\n",
       "  'index': 19,\n",
       "  'word': 'dem',\n",
       "  'start': 97,\n",
       "  'end': 100},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.59496284,\n",
       "  'index': 20,\n",
       "  'word': 'Prüfungs',\n",
       "  'start': 101,\n",
       "  'end': 109},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.5091417,\n",
       "  'index': 21,\n",
       "  'word': '##ergebnis',\n",
       "  'start': 109,\n",
       "  'end': 117},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.5981462,\n",
       "  'index': 22,\n",
       "  'word': 'des',\n",
       "  'start': 118,\n",
       "  'end': 121},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.522343,\n",
       "  'index': 23,\n",
       "  'word': 'Stadt',\n",
       "  'start': 122,\n",
       "  'end': 127},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.5395832,\n",
       "  'index': 24,\n",
       "  'word': '##rechnungs',\n",
       "  'start': 127,\n",
       "  'end': 136},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.6731845,\n",
       "  'index': 25,\n",
       "  'word': '##hof',\n",
       "  'start': 136,\n",
       "  'end': 139},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.54259264,\n",
       "  'index': 26,\n",
       "  'word': '##es',\n",
       "  'start': 139,\n",
       "  'end': 141},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.5540764,\n",
       "  'index': 27,\n",
       "  'word': 'Wien',\n",
       "  'start': 142,\n",
       "  'end': 146},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.55507576,\n",
       "  'index': 28,\n",
       "  'word': 'überein',\n",
       "  'start': 147,\n",
       "  'end': 154},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.6332131,\n",
       "  'index': 29,\n",
       "  'word': '##stimm',\n",
       "  'start': 154,\n",
       "  'end': 159},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.64609826,\n",
       "  'index': 30,\n",
       "  'word': '##te',\n",
       "  'start': 159,\n",
       "  'end': 161},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.52732676,\n",
       "  'index': 31,\n",
       "  'word': ',',\n",
       "  'start': 162,\n",
       "  'end': 163},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.55268425,\n",
       "  'index': 32,\n",
       "  'word': 'bzw',\n",
       "  'start': 164,\n",
       "  'end': 167},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.54643416,\n",
       "  'index': 33,\n",
       "  'word': '.',\n",
       "  'start': 167,\n",
       "  'end': 168},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.5710853,\n",
       "  'index': 34,\n",
       "  'word': 'waren',\n",
       "  'start': 169,\n",
       "  'end': 174},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.6309036,\n",
       "  'index': 35,\n",
       "  'word': 'drei',\n",
       "  'start': 175,\n",
       "  'end': 179},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.56868106,\n",
       "  'index': 36,\n",
       "  'word': 'als',\n",
       "  'start': 180,\n",
       "  'end': 183},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.5286014,\n",
       "  'index': 37,\n",
       "  'word': 'in',\n",
       "  'start': 184,\n",
       "  'end': 186},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.54368514,\n",
       "  'index': 38,\n",
       "  'word': 'Umsetzung',\n",
       "  'start': 187,\n",
       "  'end': 196},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.66480947,\n",
       "  'index': 39,\n",
       "  'word': 'gemeldet',\n",
       "  'start': 197,\n",
       "  'end': 205},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.69192207,\n",
       "  'index': 40,\n",
       "  'word': '##e',\n",
       "  'start': 205,\n",
       "  'end': 206},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.6211502,\n",
       "  'index': 41,\n",
       "  'word': 'Empfehlungen',\n",
       "  'start': 207,\n",
       "  'end': 219},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.60587215,\n",
       "  'index': 42,\n",
       "  'word': 'zwischen',\n",
       "  'start': 220,\n",
       "  'end': 228},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.50854707,\n",
       "  'index': 43,\n",
       "  'word': '##zeitlich',\n",
       "  'start': 228,\n",
       "  'end': 236},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.5864804,\n",
       "  'index': 44,\n",
       "  'word': 'bereits',\n",
       "  'start': 237,\n",
       "  'end': 244},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.59624475,\n",
       "  'index': 45,\n",
       "  'word': 'umgesetzt',\n",
       "  'start': 245,\n",
       "  'end': 254},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.50406504,\n",
       "  'index': 46,\n",
       "  'word': 'und',\n",
       "  'start': 255,\n",
       "  'end': 258},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.53862995,\n",
       "  'index': 47,\n",
       "  'word': 'zwei',\n",
       "  'start': 259,\n",
       "  'end': 263},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.5648712,\n",
       "  'index': 48,\n",
       "  'word': 'geplante',\n",
       "  'start': 264,\n",
       "  'end': 272},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.63877386,\n",
       "  'index': 49,\n",
       "  'word': 'Umsetzung',\n",
       "  'start': 273,\n",
       "  'end': 282},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.6620342,\n",
       "  'index': 50,\n",
       "  'word': '##en',\n",
       "  'start': 282,\n",
       "  'end': 284},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.57388425,\n",
       "  'index': 51,\n",
       "  'word': 'zwischen',\n",
       "  'start': 285,\n",
       "  'end': 293},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.5101487,\n",
       "  'index': 52,\n",
       "  'word': '##zeitlich',\n",
       "  'start': 293,\n",
       "  'end': 301},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.54893154,\n",
       "  'index': 53,\n",
       "  'word': 'bereits',\n",
       "  'start': 302,\n",
       "  'end': 309},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.5022217,\n",
       "  'index': 54,\n",
       "  'word': 'in',\n",
       "  'start': 310,\n",
       "  'end': 312},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.52633905,\n",
       "  'index': 55,\n",
       "  'word': 'Umsetzung',\n",
       "  'start': 313,\n",
       "  'end': 322},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.5215322,\n",
       "  'index': 56,\n",
       "  'word': '.',\n",
       "  'start': 323,\n",
       "  'end': 324}]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# pipe = pipeline(\"ner\", model=model_checkpoint, tokenizer=tokenizer)\n",
    "# test_text = ' '.join(dset['test'][0]['tokens'])\n",
    "\n",
    "# test_result = pipe(test_text)\n",
    "# test_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
