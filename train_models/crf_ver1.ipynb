{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd9073c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sooje\\anaconda3\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file...\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "# !python -m spacy download de_core_news_sm\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "def get_data(path):\n",
    "    print(\"Reading file...\")\n",
    "    with open(path,'r', encoding = 'utf-8') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "    return data\n",
    "path = 'all.jsonl'\n",
    "data = get_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3414f405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['00', '00', '00', '00', '00', '00', '00', '00'],\n",
       " ['Maßnahmenbekanntgabe',\n",
       "  'zu',\n",
       "  'MA',\n",
       "  '40',\n",
       "  ',',\n",
       "  'Prüfung',\n",
       "  'der',\n",
       "  'Nebenbeschäftigungen'],\n",
       " ['NN', 'APPR', 'NE', 'CARD', '$,', 'NN', 'ART', 'NN'],\n",
       " ['O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def iob(d):\n",
    "    count = 0 \n",
    "    i=0\n",
    "    starts = [x['start_offset'] for x in d['entities']]\n",
    "    ends = [x['end_offset'] for x in d['entities']]\n",
    "    starts.append(99999)\n",
    "    ends.append(99999)\n",
    "\n",
    "    sen_temp = []\n",
    "    tag_temp = []\n",
    "\n",
    "    \n",
    "    text = d['text']\n",
    "    if text.startswith(\" \"):\n",
    "        text = text[1:]\n",
    "        count = 1\n",
    "    doc = nlp(text)\n",
    "    pos = [token.tag_ for token in doc]\n",
    "\n",
    "    for t in doc:\n",
    "        sen_temp.append(t.text)\n",
    "        if count == starts[i]:\n",
    "            tag_temp.append('B-ORG')\n",
    "            count = count+len(t.text)+1\n",
    "            if count > ends[i]:\n",
    "                i += 1\n",
    "\n",
    "        elif count > starts[i] and count < ends[i]:\n",
    "            if tag_temp[-1] == 'O':\n",
    "                tag_temp.append('B-ORG')\n",
    "            else:\n",
    "                tag_temp.append('I-ORG')\n",
    "            count = count+len(t.text)+1\n",
    "            if count > ends[i]:\n",
    "                i += 1\n",
    "\n",
    "        else:\n",
    "            tag_temp.append('O')\n",
    "            count = count+len(t.text)+1\n",
    "    token_nums = len(tag_temp)\n",
    "    doc_id_temp = [str(d['doc_id'])+str(d['para_id'])] * token_nums\n",
    "#     para_id_temp = [d['para_id']] * token_nums\n",
    "    return doc_id_temp, sen_temp, pos, tag_temp\n",
    "\n",
    "iob(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f50d17bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 51631, 'label': 'ORG', 'start_offset': 24, 'end_offset': 29}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f46c03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_output(data):\n",
    "    print('Tokenizing...')\n",
    "    doc_id_list = []\n",
    "    para_id_list = []\n",
    "    txt_list = []\n",
    "    pos_list = []\n",
    "    tag_list = []\n",
    "\n",
    "    for k in data:\n",
    "#         doc_id_list.append(d['doc_id'])\n",
    "#         para_id_list.append(d['para_id']\n",
    "        \n",
    "        docu, txt, pos, tag = iob(k)\n",
    "        for i in range(len(docu)):\n",
    "            doc_id_list.append(docu[i])\n",
    "#             para_id_list.append(para[i])\n",
    "            txt_list.append(txt[i])\n",
    "            pos_list.append(pos[i])\n",
    "            tag_list.append(tag[i])\n",
    "#         txt_list.append(txt)\n",
    "#         tag_list.append(tag)\n",
    "    \n",
    "    tokenized = pd.DataFrame({'doc_id' : doc_id_list,\n",
    "#                              'para_id': para_id_list,\n",
    "                             'tokens' : txt_list,\n",
    "                              'pos_tags' : pos_list,\n",
    "                             'ner_tags' : tag_list})\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7fb0a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n"
     ]
    }
   ],
   "source": [
    "df = tokenized_output(data)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae4168b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-ORG', 'I-ORG']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = list(df['ner_tags'].unique())\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d17ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding_dict = {'O': 0,'B-ORG':1,'I-ORG':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ed9627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c97e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from transformers import AutoTokenizer\n",
    "# import os\n",
    "# os.environ['TRANSFORMERS_CACHE'] = './cache'\n",
    "# from transformers import LukeTokenizer, LukeModel, LukeForEntityPairClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bce6110",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sentence(object):\n",
    "    def __init__(self, df):\n",
    "        self.n_sent = 0\n",
    "        self.df = df\n",
    "        self.empty = False\n",
    "        agg = lambda s : [(w, p, t) for w, p, t in zip(s['tokens'].values.tolist(),\n",
    "                                                       s['pos_tags'].values.tolist(),\n",
    "                                                       s['ner_tags'].values.tolist())]\n",
    "        self.grouped = self.df.groupby(\"doc_id\").apply(agg)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_text(self):\n",
    "        id_list = list(df['doc_id'].unique())\n",
    "        \n",
    "        try:\n",
    "            s = self.grouped[id_list[self.n_sent]]\n",
    "            self.n_sent +=1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09b63d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Maßnahmenbekanntgabe zu MA 40 , Prüfung der Nebenbeschäftigungen'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getter = sentence(df)\n",
    "sentences = [\" \".join([s[0] for s in sent]) for sent in getter.sentences]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdfb5148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Maßnahmenbekanntgabe', 'NN', 'O'), ('zu', 'APPR', 'O'), ('MA', 'NE', 'B-ORG'), ('40', 'CARD', 'I-ORG'), (',', '$,', 'O'), ('Prüfung', 'NN', 'O'), ('der', 'ART', 'O'), ('Nebenbeschäftigungen', 'NN', 'O')]\n"
     ]
    }
   ],
   "source": [
    "sent = getter.get_text()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a28613ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Maßnahmenbekanntgabe', 'NN', 'O'),\n",
       " ('zu', 'APPR', 'O'),\n",
       " ('MA', 'NE', 'B-ORG'),\n",
       " ('40', 'CARD', 'I-ORG'),\n",
       " (',', '$,', 'O'),\n",
       " ('Prüfung', 'NN', 'O'),\n",
       " ('der', 'ART', 'O'),\n",
       " ('Nebenbeschäftigungen', 'NN', 'O')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = getter.sentences\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b35774ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40061984",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "181dbd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bias': 1.0, 'word.lower()': 'maßnahmenbekanntgabe', 'word[-3:]': 'abe', 'word[-2:]': 'be', 'word.isupper()': False, 'word.istitle()': True, 'word.isdigit()': False, 'postag': 'NN', 'postag[:2]': 'NN', 'BOS': True, '+1:word.lower()': 'zu', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'APPR', '+1:postag[:2]': 'AP'}, {'bias': 1.0, 'word.lower()': 'zu', 'word[-3:]': 'zu', 'word[-2:]': 'zu', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'APPR', 'postag[:2]': 'AP', '-1:word.lower()': 'maßnahmenbekanntgabe', '-1:word.istitle()': True, '-1:word.isupper()': False, '-1:postag': 'NN', '-1:postag[:2]': 'NN', '+1:word.lower()': 'ma', '+1:word.istitle()': False, '+1:word.isupper()': True, '+1:postag': 'NE', '+1:postag[:2]': 'NE'}, {'bias': 1.0, 'word.lower()': 'ma', 'word[-3:]': 'MA', 'word[-2:]': 'MA', 'word.isupper()': True, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'NE', 'postag[:2]': 'NE', '-1:word.lower()': 'zu', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'APPR', '-1:postag[:2]': 'AP', '+1:word.lower()': '40', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'CARD', '+1:postag[:2]': 'CA'}, {'bias': 1.0, 'word.lower()': '40', 'word[-3:]': '40', 'word[-2:]': '40', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': True, 'postag': 'CARD', 'postag[:2]': 'CA', '-1:word.lower()': 'ma', '-1:word.istitle()': False, '-1:word.isupper()': True, '-1:postag': 'NE', '-1:postag[:2]': 'NE', '+1:word.lower()': ',', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': '$,', '+1:postag[:2]': '$,'}, {'bias': 1.0, 'word.lower()': ',', 'word[-3:]': ',', 'word[-2:]': ',', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': '$,', 'postag[:2]': '$,', '-1:word.lower()': '40', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'CARD', '-1:postag[:2]': 'CA', '+1:word.lower()': 'prüfung', '+1:word.istitle()': True, '+1:word.isupper()': False, '+1:postag': 'NN', '+1:postag[:2]': 'NN'}, {'bias': 1.0, 'word.lower()': 'prüfung', 'word[-3:]': 'ung', 'word[-2:]': 'ng', 'word.isupper()': False, 'word.istitle()': True, 'word.isdigit()': False, 'postag': 'NN', 'postag[:2]': 'NN', '-1:word.lower()': ',', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': '$,', '-1:postag[:2]': '$,', '+1:word.lower()': 'der', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'ART', '+1:postag[:2]': 'AR'}, {'bias': 1.0, 'word.lower()': 'der', 'word[-3:]': 'der', 'word[-2:]': 'er', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'ART', 'postag[:2]': 'AR', '-1:word.lower()': 'prüfung', '-1:word.istitle()': True, '-1:word.isupper()': False, '-1:postag': 'NN', '-1:postag[:2]': 'NN', '+1:word.lower()': 'nebenbeschäftigungen', '+1:word.istitle()': True, '+1:word.isupper()': False, '+1:postag': 'NN', '+1:postag[:2]': 'NN'}, {'bias': 1.0, 'word.lower()': 'nebenbeschäftigungen', 'word[-3:]': 'gen', 'word[-2:]': 'en', 'word.isupper()': False, 'word.istitle()': True, 'word.isdigit()': False, 'postag': 'NN', 'postag[:2]': 'NN', '-1:word.lower()': 'der', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'ART', '-1:postag[:2]': 'AR', 'EOS': True}]\n",
      "['O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b810a377",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d8f3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(algorithm = 'lbfgs',\n",
    "         c1 = 0.1,\n",
    "         c2 = 0.1,\n",
    "         max_iterations = 100,\n",
    "         all_possible_transitions = False)\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "    pass\n",
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aba8d869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"git+'https://github.com/MeMartijn/updated-sklearn-crfsuite.git#egg=sklearn_crfsuite'\"\n",
      "Hint: = is not a valid operator. Did you mean == ?\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/MeMartijn/updated-sklearn-crfsuite.git#egg=sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc942dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-ORG', 'I-ORG']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tags = crf.classes_\n",
    "unique_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8903da6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-ORG       0.71      0.70      0.71       644\n",
      "       I-ORG       0.71      0.72      0.72       741\n",
      "           O       0.99      0.99      0.99     34703\n",
      "\n",
      "    accuracy                           0.98     36088\n",
      "   macro avg       0.81      0.80      0.80     36088\n",
      "weighted avg       0.98      0.98      0.98     36088\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from  sklearn_crfsuite.metrics import flat_classification_report  \n",
    "import itertools\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "unique_tags = crf.classes_\n",
    "y_test_flat = list(itertools.chain.from_iterable(y_test))\n",
    "y_pred_flat = list(itertools.chain.from_iterable(y_pred))\n",
    "\n",
    "print(classification_report(y_test_flat, y_pred_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50204de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ORG       0.66      0.64      0.65       644\n",
      "\n",
      "   micro avg       0.66      0.64      0.65       644\n",
      "   macro avg       0.66      0.64      0.65       644\n",
      "weighted avg       0.66      0.64      0.65       644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
